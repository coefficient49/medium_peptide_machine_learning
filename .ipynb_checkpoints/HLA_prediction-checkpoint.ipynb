{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data wrangling\n",
    "from util_tools import *\n",
    "import util_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## for reproducibility\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "\n",
    "## for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr,pearsonr,zscore\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have entered an incorrect embedding option, currently, this script only take \"onehot\" or \"blosum62\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util_tools.encoder at 0x7f83358e3390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util_tools.encoder(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(pd.read_csv(\"curated_training_data.affinity.csv\").allele)\n",
    "df = pd.read_csv(\"curated_training_data.affinity.csv\").query(\"allele == 'HLA-A*02:01'\")\n",
    "seqs = df.peptide\n",
    "meas = df.measurement_value\n",
    "sns.distplot(meas.apply(np.log10).replace(-np.inf,0))\n",
    "seqspep = seqs[[x==9 for x in map(len,seqs)]]\n",
    "meas = meas[[x==9 for x in map(len,seqs)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ic50(ic50, max_ic50=50000.0):\n",
    "    \"\"\"\n",
    "    Convert ic50s to regression targets in the range [0.0, 1.0].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ic50 : numpy.array of float\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array of float\n",
    "    \"\"\"\n",
    "    x = 1.0 - (np.log(np.maximum(ic50, 1e-12)) / np.log(max_ic50))\n",
    "    return np.minimum(\n",
    "        1.0,\n",
    "        np.maximum(0.0, x))\n",
    "\n",
    "\n",
    "def to_ic50(x, max_ic50=50000.0):\n",
    "    \"\"\"\n",
    "    Convert regression targets in the range [0.0, 1.0] to ic50s in the range\n",
    "    [0, 50000.0].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.array of float\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array of float\n",
    "    \"\"\"\n",
    "    return max_ic50 ** (1.0 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,testing=get_HLA_A_02_01()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution exploration.\n",
    "\n",
    "Take a look at the measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(testing.loc[:,\"Measurement value\"].apply(np.log10).replace(-np.inf,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peptide_9mers.loc[:,\"meas\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = encoder(\"onehot\")\n",
    "blosum = encoder(\"blosum62\")\n",
    "reducedProp =encoder(\"reducedProp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Peptide_9mers = training.query(\"peptide_length == 9\")\n",
    "seqs = Peptide_9mers.loc[:,\"sequence\"]\n",
    "off_set = Peptide_9mers[\"inequality\"].map({\"=\":0,\">\":2,\"<\":4})\n",
    "# meas = Peptide_9mers.loc[:,\"meas\"].apply(np.log10)\n",
    "meas = from_ic50(Peptide_9mers.loc[:,\"meas\"]) +off_set\n",
    "# seqs = seqspep\n",
    "# Peptide_9mers\n",
    "blosum_seqs = [blosum.encode(x) for x in seqs]\n",
    "onehot_seqs = [onehot.encode(x) for x in seqs]\n",
    "reducedProp_seqs = [reducedProp.encode(x) for x in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(from_ic50(Peptide_9mers.loc[:,\"meas\"]))\n",
    "\n",
    "#   '=': 0,\n",
    "#                 '>': 2,\n",
    "#                 '<': 4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(encoder_type = \"blosum62\", conv_layers = True):\n",
    "    if encoder_type == \"onehot\":\n",
    "        inputs = Input(shape=(20,9,1))\n",
    "    elif encoder_type == \"blosum62\":\n",
    "        inputs = Input(shape=(24,9,1))\n",
    "    elif encoder_type == \"reducedProp\":\n",
    "        inputs = Input(shape=(6,9,1))\n",
    "    \n",
    "    if conv_layers:\n",
    "        hidden1 = Conv2D(16,7,activation=\"relu\",padding=\"same\")(inputs)\n",
    "        hidden2 = Conv2D(8,5,activation=\"relu\",padding=\"same\")(hidden1)\n",
    "        hidden3 = Conv2D(4,5,activation=\"relu\",padding=\"same\")(hidden2)\n",
    "        hidden4 = Conv2D(2,3,activation=\"relu\",padding=\"same\")(hidden3)\n",
    "        flatten = Flatten()(hidden4)\n",
    "    else:\n",
    "        flatten = Flatten()(inputs)\n",
    "        \n",
    "    dense1  = Dense(200,activation=\"relu\")(flatten)\n",
    "    dense1  = BatchNormalization()(dense1)\n",
    "    dense1  = Dropout(0.7)(dense1)\n",
    "\n",
    "    dense2  = Dense(200,activation=\"relu\")(dense1)\n",
    "    dense2  = BatchNormalization()(dense2)\n",
    "    dense2  = Dropout(0.8)(dense2)\n",
    "\n",
    "    dense3  = Dense(100,activation=\"relu\")(dense2)\n",
    "    dense3  = BatchNormalization()(dense3)\n",
    "    dense3  = Dropout(0.8)(dense3)\n",
    "    \n",
    "    dense4  = Dense(50,activation=\"relu\")(dense3)\n",
    "    dense4  = BatchNormalization()(dense4)\n",
    "    dense4  = Dropout(0.8)(dense4)\n",
    "    \n",
    "    dense5  = Dense(25,activation=\"relu\")(dense4)\n",
    "    dense5  = BatchNormalization()(dense5)\n",
    "    dense5  = Dropout(0.8)(dense5)\n",
    "\n",
    "    outputs = Dense(1,activation=\"linear\")(dense5)\n",
    "\n",
    "    # dense3\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def SPRCC(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "\n",
    "    # Handle (=) inequalities\n",
    "    diff1 =  y_true\n",
    "    diff1 *= K.cast(y_true >= 0.0, \"float32\")\n",
    "    diff1 *= K.cast(y_true <= 1.0, \"float32\")\n",
    "\n",
    "    # Handle (>) inequalities\n",
    "    diff2 = y_true - 2.0\n",
    "    diff2 *= K.cast(y_true >= 2.0, \"float32\")\n",
    "    diff2 *= K.cast(y_true <= 3.0, \"float32\")\n",
    "    diff2 *= K.cast(diff2 > 0.0, \"float32\")\n",
    "\n",
    "    # Handle (<) inequalities\n",
    "    diff3 = y_true - 4.0\n",
    "    diff3 *= K.cast(y_true >= 4.0, \"float32\")\n",
    "    diff3 *= K.cast(diff3 > 0.0, \"float32\")\n",
    "    \n",
    "    y_true = diff1 + diff2 + diff3\n",
    "    \n",
    "    return ( tf.py_function(spearmanr, [tf.cast(y_pred, tf.float32),tf.cast(y_true, tf.float32)], Tout = tf.float32) )\n",
    "\n",
    "def inequaility_loss(y_true, y_pred):\n",
    "    # We always delay import of Keras so that mhcflurry can be imported\n",
    "    # initially without tensorflow debug output, etc.\n",
    "    from tensorflow.keras import backend as K\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "\n",
    "    # Handle (=) inequalities\n",
    "    diff1 = y_pred - y_true\n",
    "    diff1 *= K.cast(y_true >= 0.0, \"float32\")\n",
    "    diff1 *= K.cast(y_true <= 1.0, \"float32\")\n",
    "\n",
    "    # Handle (>) inequalities\n",
    "    diff2 = y_pred - (y_true - 2.0)\n",
    "    diff2 *= K.cast(y_true >= 2.0, \"float32\")\n",
    "    diff2 *= K.cast(y_true <= 3.0, \"float32\")\n",
    "    diff2 *= K.cast(diff2 > 0.0, \"float32\")\n",
    "\n",
    "    # Handle (<) inequalities\n",
    "    diff3 = y_pred - (y_true - 4.0)\n",
    "    diff3 *= K.cast(y_true >= 4.0, \"float32\")\n",
    "    diff3 *= K.cast(diff3 > 0.0, \"float32\")\n",
    "\n",
    "    denominator = K.maximum(\n",
    "        K.sum(K.cast(K.not_equal(y_true, 2.0), \"float32\"), 0),\n",
    "        1.0)\n",
    "\n",
    "    result = (\n",
    "            K.sum(K.square(diff1)) +\n",
    "            K.sum(K.square(diff2)) +\n",
    "            K.sum(K.square(diff3))) / denominator\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "######### model parameters ##############\n",
    "epochs = 5000\n",
    "batch_size = 64\n",
    "patience = 20\n",
    "\n",
    "########################################\n",
    "\n",
    "def train_test_model(model_type = \"blosum62\",conv=True, epochs = 100, batch_size = 16, patience=2, optimizer= \"nadam\"):\n",
    "    \n",
    "    if model_type == \"blosum62\":\n",
    "        X = np.array(blosum_seqs).reshape(-1,24,9,1)\n",
    "    elif model_type == \"onehot\":\n",
    "        X = np.array(onehot_seqs).reshape(-1,20,9,1)\n",
    "    elif model_type == \"reducedProp\":\n",
    "        X = np.array(reducedProp_seqs).reshape(-1,6,9,1)\n",
    "    \n",
    "#     Y = Peptide_9mers.loc[:,\"meas\"].apply(np.log10)\n",
    "    Y = meas\n",
    "    \n",
    "    model = build_model(model_type)\n",
    "    model.compile(\n",
    "        loss=inequaility_loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[SPRCC]\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss',mode=\"min\",patience=patience)\n",
    "    mc = ModelCheckpoint('best_{}_conv={}_model.h5'.format(model_type,conv),monitor='val_loss', mode='min', save_best_only=True)\n",
    "    [X_train, X_test, y_train, y_test]=train_test_split(X,Y,test_size=0.2,random_state=10)\n",
    "    history = model.fit(X_train,y_train,batch_size=batch_size,epochs = epochs, validation_split=0.1,callbacks=[es,mc])\n",
    "    return (history,model,X_test,y_test)\n",
    "\n",
    "def plot_model(history=False,model=None,X_test=None,y_test=None):\n",
    "    if history:\n",
    "        plt.figure()\n",
    "        sns.lineplot(data=pd.DataFrame(history.history).reset_index(),x=\"index\",y=\"loss\")\n",
    "        sns.lineplot(data=pd.DataFrame(history.history).reset_index(),x=\"index\",y=\"val_loss\")\n",
    "        plt.legend([\"loss\",\"val_loss\"])\n",
    "    y_pred = model.predict(X_test)\n",
    "    ## transform y_test\n",
    "    \n",
    "    bat1 = y_test*(y_test<=1)\n",
    "    bat2 = (y_test-2)*(y_test>=2)*(y_test<=3)\n",
    "    bat3 = (y_test-4)*(y_test>=4)\n",
    "    y_test = bat1+bat2+bat3\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=y_test,y=y_pred.squeeze())\n",
    "    R, pv = spearmanr(y_test,y_pred.squeeze())\n",
    "    plt.title(\"SRCC: {0:0.4f}\".format(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"onehot\"\n",
    "# conv=True, \n",
    "# epochs = 1 \n",
    "# batch_size = 32\n",
    "# patience=50\n",
    "# optimizer= \"nadam\"\n",
    "# if model_type == \"blosum62\":\n",
    "#     X = np.array(blosum_seqs).reshape(-1,24,9,1)\n",
    "# elif model_type == \"onehot\":\n",
    "#     X = np.array(onehot_seqs).reshape(-1,20,9,1)\n",
    "# elif model_type == \"reducedProp\":\n",
    "#     X = np.array(reducedProp_seqs).reshape(-1,6,9,1)\n",
    "\n",
    "# #     Y = Peptide_9mers.loc[:,\"meas\"].apply(np.log10)\n",
    "# Y = meas\n",
    "\n",
    "# model = build_model(model_type)\n",
    "# model.compile(\n",
    "#     loss=\"MSE\",\n",
    "#     optimizer=optimizer,\n",
    "#     metrics=[SPRCC]\n",
    "# )\n",
    "# es = EarlyStopping(monitor='val_loss',mode=\"min\",patience=patience)\n",
    "# mc = ModelCheckpoint('best_{}_conv={}_model.h5'.format(model_type,conv),monitor='val_loss', mode='min', save_best_only=True)\n",
    "# [X_train, X_test, y_train, y_test]=train_test_split(X,Y,test_size=0.2,random_state=10)\n",
    "\n",
    "# history = model.fit(X_train,y_train,batch_size=batch_size,epochs = epochs, validation_split=0.1,callbacks=[es,mc])\n",
    "# return (history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(50):\n",
    "#     history = model.fit(X_train,y_train,batch_size=batch_size,epochs = epochs, validation_split=0.1,callbacks=[es,mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train,y_train,batch_size=batch_size,epochs = epochs, validation_split=0.1,callbacks=[es,mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"blosum62\",\n",
    "                                               conv=True, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"onehot\",\n",
    "                                               conv=True, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"reducedProp\",\n",
    "                                               conv=True, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"blosum62\",\n",
    "                                               conv=False, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"onehot\",\n",
    "                                               conv=False, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "tensorflow.random.set_seed(123454566)\n",
    "\n",
    "history,model,X_test,y_test = train_test_model(model_type = \"reducedProp\",\n",
    "                                               conv=False, \n",
    "                                               epochs = epochs, \n",
    "                                               batch_size = batch_size, \n",
    "                                               patience=patience, \n",
    "                                               optimizer= \"nadam\")\n",
    "plot_model(history,model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(history,model,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "set_random_seed(123454566)\n",
    "\n",
    "X = np.array(reducedProp_seqs).reshape(-1,54)\n",
    "Y = Peptide_9mers.loc[:,\"meas\"].apply(np.log10)\n",
    "# Y = meas.apply(np.log10)\n",
    "[X_train, X_test, y_train, y_test]=train_test_split(X,Y,test_size=0.2,random_state=10)\n",
    "model = xgb.XGBRegressor(n_estimators=150)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[10**x for x in model.predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=y_test,y=y_pred.squeeze())\n",
    "R, pv = spearmanr(y_test,y_pred.squeeze())\n",
    "plt.title(\"SRCC: {0:0.4f}\".format(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(123454566)\n",
    "set_random_seed(123454566)\n",
    "\n",
    "X = np.array(reducedProp_seqs).reshape(-1,54)\n",
    "Y = Peptide_9mers.loc[:,\"meas\"].apply(np.log10)\n",
    "[X_train, X_test, y_train, y_test]=train_test_split(seqs,Y,test_size=0.2,random_state=10)\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep = \"\"\n",
    "for x in X_test:\n",
    "    pep += x + \" \"\n",
    "# pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhcflurry = list(pd.read_csv(\"/mnt/e/OneDrive/hobby_Project/mhcflurry_prediction.csv\").mhcflurry_affinity.apply(np.log10))\n",
    "sns.scatterplot(x=y_test,y=mhcflurry)\n",
    "spearmanr(y_test,mhcflurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
